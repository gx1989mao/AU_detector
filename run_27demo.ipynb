{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94236ca",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0783b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from dataset import pil_loader\n",
    "from model.ANFL import MEFARG\n",
    "from utils import *\n",
    "from conf import get_config,set_logger,set_outdir,set_env\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import mediapipe as mp\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c69e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AU_name_lists = ['Inner brow raiser',\n",
    "        'Outer brow raiser',\n",
    "        'Brow lowerer',\n",
    "        'Upper lid raiser',\n",
    "        'Cheek raiser',\n",
    "        'Lid tightener',\n",
    "        'Nose wrinkler',\n",
    "        'Upper lip raiser',\n",
    "        'Nasolabial deepener',\n",
    "        'Lip corner puller',\n",
    "        'Sharp lip puller',\n",
    "        'Dimpler',\n",
    "        'Lip corner depressor',\n",
    "        'Lower lip depressor',\n",
    "        'Chin raiser',\n",
    "        'Lip pucker',\n",
    "        'Tongue show',\n",
    "        'Lip stretcher',\n",
    "        'Lip funneler',\n",
    "        'Lip tightener',\n",
    "        'Lip pressor',\n",
    "        'Lips part',\n",
    "        'Jaw drop',\n",
    "        'Mouth stretch',\n",
    "        'Lip bite',\n",
    "        'Nostril dilator',\n",
    "        'Nostril compressor',\n",
    "        'Left Inner brow raiser',\n",
    "        'Right Inner brow raiser',\n",
    "        'Left Outer brow raiser',\n",
    "        'Right Outer brow raiser',\n",
    "        'Left Brow lowerer',\n",
    "        'Right Brow lowerer',\n",
    "        'Left Cheek raiser',\n",
    "        'Right Cheek raiser',\n",
    "        'Left Upper lip raiser',\n",
    "        'Right Upper lip raiser',\n",
    "        'Left Nasolabial deepener',\n",
    "        'Right Nasolabial deepener',\n",
    "        'Left Dimpler',\n",
    "        'Right Dimpler']\n",
    "\n",
    "AU_name_lists1 =  ['AU1:','AU2:','AU4:','AU5:','AU6:','AU7:','AU9:','AU10:','AU11:',\n",
    "      'AU12:','AU13:','AU14:','AU15:','AU16:','AU17:','AU18:','AU19:','AU20:',\n",
    "      'AU22:','AU23:','AU24:','AU25:','AU26:','AU27:','AU32:','AU38:','AU39:',\n",
    "      'AUL1:','AUR1:','AUL2:','AUR2:','AUL4:','AUR4:','AUL6:','AUR6:','AUL10:',\n",
    "      'AUR10:','AUL12:','AUR12:','AUL14:','AUR14:']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e337736",
   "metadata": {},
   "source": [
    "# prepare net and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7005c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net():\n",
    "    path = \"./checkpoints/OpenGprahAU-ResNet50_first_stage.pth\"\n",
    "    net = MEFARG(num_main_classes=27, num_sub_classes=14, backbone=\"resnet\", neighbor_num=4)\n",
    "    net = load_state_dict(net, path)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6006db4",
   "metadata": {},
   "source": [
    "# face align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6a0202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ang(p1, p2):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    tan = (y2 - y1) / (x2 - x1)\n",
    "    return np.degrees(np.arctan(tan))\n",
    "\n",
    "def get_rotation_matrix(p1, p2):\n",
    "    angle = ang(p1, p2)\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    xc = (x1 + x2) // 2\n",
    "    yc = (y1 + y2) // 2\n",
    "    M = cv2.getRotationMatrix2D((xc, yc), angle, 1)\n",
    "    return M\n",
    "\n",
    "\n",
    "def cal(M,P,B,scale=1):\n",
    "    eye_cent = (P[0,:]+P[1,:])/2\n",
    "    nose_cent = (eye_cent+P[3,:])/2\n",
    "    cent = M@np.append(nose_cent,[1])\n",
    "    half = int(np.linalg.norm(eye_cent-P[3,:])*3/2*scale)\n",
    "    half = (half,half)\n",
    "    return cent.astype(np.int32), half\n",
    "\n",
    "def crop_image(image,M,P,B):\n",
    "    h, w = image.shape[:2]\n",
    "    cent, half = cal(M,P,B)\n",
    "    cx,cy = cent\n",
    "    half_h,half_w = half\n",
    "    \n",
    "    x0 = cx-half_w if cx-half_w>=0 else 0\n",
    "    x1 = cx+half_w if cx+half_w<=w else w\n",
    "    y0 = cy-half_h if cy-half_h>=0 else 0\n",
    "    y1 = cy+half_h if cy+half_h<=h else h\n",
    "    return image[y0:y1,x0:x1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d84a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_align(image):\n",
    "    height, width = image.shape[:2]\n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "        image.flags.writeable = False\n",
    "        results = face_detection.process(image)\n",
    "    \n",
    "        if results.detections:\n",
    "            points = results.detections[0].location_data.relative_keypoints\n",
    "            P = []\n",
    "            for i in range(6):\n",
    "                P.append((points[i].x*width,points[i].y*height))\n",
    "            P = np.array(P)\n",
    "            bbox = results.detections[0].location_data.relative_bounding_box\n",
    "            B = []\n",
    "            B.append(bbox.xmin*width)\n",
    "            B.append(bbox.ymin*height)\n",
    "            B.append(bbox.width*width)\n",
    "            B.append(bbox.height*height)\n",
    "            B = np.array(B)\n",
    "\n",
    "            M = get_rotation_matrix(P[0], P[1])\n",
    "            res = cv2.warpAffine(image, M, (width,height), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "            res = crop_image(res,M,P,B)\n",
    "            return res\n",
    "        else:\n",
    "            return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3da2a",
   "metadata": {},
   "source": [
    "# pretty draw AU inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f624552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_draw(image,pred):\n",
    "    image = cv2.resize(np.array(image),(480,480))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR )\n",
    "    dataset_info = hybrid_prediction_infolist\n",
    "    infostr_probs,  infostr_aus = dataset_info(pred, 0.5)\n",
    "    blank = np.ones((480, 640, 3),np.uint8)*255\n",
    "    for i in range(21):\n",
    "        text = AU_name_lists[i]+AU_name_lists1[i]\n",
    "        if pred[i]>0.5:\n",
    "            color = (255,0,0)\n",
    "        else:\n",
    "            color = (255,255,0)\n",
    "        posi = (0,20*i+20)\n",
    "        cv2.putText(blank,text,posi,cv2.FONT_HERSHEY_COMPLEX,0.4,color,1)\n",
    "    for i in range(22,41):\n",
    "        text = AU_name_lists[i]+AU_name_lists1[i]\n",
    "        if pred[i]>0.5:\n",
    "            color = (255,0,0)\n",
    "        else:\n",
    "            color = (255,255,0)\n",
    "        posi = (320,20*(i-22)+20)\n",
    "        cv2.putText(blank,text,posi,cv2.FONT_HERSHEY_COMPLEX,0.4,color,1)   \n",
    "    return np.hstack((image,blank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a7fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = 0\n",
    "def pipeline(image):\n",
    "    img_transform = image_eval()\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB )\n",
    "    img = face_align(img)\n",
    "    img = Image.fromarray(img)\n",
    "#     img = pil_loader('./demo_imgs/1014.jpg').rotate(0)\n",
    "    \n",
    "    img_ = img_transform(img).unsqueeze(0)\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        global pred\n",
    "        pred = net(img_)\n",
    "        pred = pred.squeeze().cpu().numpy()\n",
    "        image = pretty_draw(img,pred)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93cda6",
   "metadata": {},
   "source": [
    "# close camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfb85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408ae56",
   "metadata": {},
   "source": [
    "# cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0239372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = make_net()\n",
    "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "# cap.set(3, 1280)  # width=1920\n",
    "# cap.set(4, 960)\n",
    "while True:\n",
    "    success, image = cap.read()\n",
    "    image = pipeline(image)\n",
    "    cv2.imshow('AU detector', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # 一帧显示一毫秒，通过上面的while循环不断地显示下一帧，从而形成动态的视频；按q键退出循环，关闭视频。\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2861b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f7344",
   "metadata": {},
   "source": [
    "# mediapipe facedec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "50c12429",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "# cap.set(3, 1280)  # width=1920\n",
    "# cap.set(4, 960)\n",
    "\n",
    "with mp_face_detection.FaceDetection(\n",
    "    model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    while True:\n",
    "        success, image = cap.read()\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(image, detection)\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14712ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = image.shape[:2]\n",
    "\n",
    "points = results.detections[0].location_data.relative_keypoints\n",
    "P = []\n",
    "for i in range(6):\n",
    "    P.append((points[i].x*width,points[i].y*height))\n",
    "P = np.array(P)\n",
    "bbox = results.detections[0].location_data.relative_bounding_box\n",
    "B = []\n",
    "B.append(bbox.xmin*width)\n",
    "B.append(bbox.ymin*height)\n",
    "B.append(bbox.width*width)\n",
    "B.append(bbox.height*height)\n",
    "B = np.array(B)\n",
    "\n",
    "M = get_rotation_matrix(P[0], P[1])\n",
    "res = cv2.warpAffine(image, M, (width,height), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "res = crop_image(res)\n",
    "Image.fromarray(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "869.6px",
    "left": "61px",
    "top": "180px",
    "width": "445.438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
